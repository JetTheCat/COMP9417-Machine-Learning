{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_85</th>\n",
       "      <th>feat_86</th>\n",
       "      <th>feat_87</th>\n",
       "      <th>feat_88</th>\n",
       "      <th>feat_89</th>\n",
       "      <th>feat_90</th>\n",
       "      <th>feat_91</th>\n",
       "      <th>feat_92</th>\n",
       "      <th>feat_93</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9068</th>\n",
       "      <td>9069</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58654</th>\n",
       "      <td>58655</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48724</th>\n",
       "      <td>48725</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24706</th>\n",
       "      <td>24707</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33471</th>\n",
       "      <td>33472</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  \\\n",
       "9068    9069       0       0       0       0       0       0       0       0   \n",
       "58654  58655       0       0       1       0       0       0       0       4   \n",
       "48724  48725       7       2       0       1       2       0       1       1   \n",
       "24706  24707       0       0       0       0       0       0       0       2   \n",
       "33471  33472       0       0       2       2       0       0       0       0   \n",
       "\n",
       "       feat_9  ...  feat_85  feat_86  feat_87  feat_88  feat_89  feat_90  \\\n",
       "9068        0  ...        0        1        0        0        0        0   \n",
       "58654       0  ...        1        2        5        0        0        0   \n",
       "48724       0  ...        3        1        0        0        0        2   \n",
       "24706       0  ...        0        1        0        0        0        0   \n",
       "33471       0  ...        0        0        1        0        0        0   \n",
       "\n",
       "       feat_91  feat_92  feat_93   target  \n",
       "9068         0        0        0  Class_2  \n",
       "58654        0        0        0  Class_9  \n",
       "48724        1        1        0  Class_8  \n",
       "24706        0        0        0  Class_3  \n",
       "33471        0        0        0  Class_6  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "import torchvision\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Gets training data, randomises and seperates into X,Y values.\n",
    "otto = pd.read_csv(\"data/train.csv\").sample(frac=1)\n",
    "ottoX = otto.iloc[:,1:-1]     # remove ID and Label \n",
    "ottoY = otto.iloc[:,-1]\n",
    "\n",
    "\n",
    "# Split data into training and validation set\n",
    "trainX, valX, trainY, valY = train_test_split(ottoX, ottoY, test_size = 0.2)\n",
    "\n",
    "otto.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert training sets into tensor form with Pytorch functions\n",
    "trainX = torch.from_numpy(trainX.values) \n",
    "valX = torch.from_numpy(valX.values)\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(trainY)\n",
    "trainY = le.transform(trainY)\n",
    "trainY = torch.from_numpy(trainY)\n",
    "\n",
    "le_val = preprocessing.LabelEncoder()\n",
    "le_val.fit(valY)\n",
    "valY = le.transform(valY)\n",
    "valY = torch.from_numpy(valY)\n",
    "\n",
    "trainX, trainY = trainX.type(torch.FloatTensor), trainY.type(torch.FloatTensor)\n",
    "valX, valY = valX.type(torch.FloatTensor), valY.type(torch.FloatTensor)\n",
    "\n",
    "\n",
    "# Load data into DataLoader\n",
    "processed_train_set = data_utils.TensorDataset(trainX, trainY)\n",
    "#processed_val_set = data_utils.TensorDataset(valX, valY)\n",
    "train_loader = data_utils.DataLoader(processed_train_set, batch_size=256, shuffle=True, drop_last=True)\n",
    "#val_loader = data_utils.DataLoader(processed_val_set, batch_size=256, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting features and label into float tensor form to be used with the TensorDataset() function later. \n",
    "\n",
    "The data is split into a training and validation set with 80/20 ratio and then fed into the TensorDataset() function to be converted into a dataset that DataLoader() can take in. \n",
    "\n",
    "Once we get the new training and validation set from TensorDataset() we used DataLoader() to split the data in each set into mini-batches of size 256 each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayered Perceptron Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, hid, dropout):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(93, hid)\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=hid)\n",
    "        self.fc2 = nn.Linear(hid, hid)\n",
    "        self.bn2 = nn.BatchNorm1d(num_features=hid)\n",
    "        self.fc3 = nn.Linear(hid, hid)\n",
    "        self.bn3 = nn.BatchNorm1d(num_features=hid)\n",
    "        self.out = nn.Linear(hid, 9)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        fc1 = self.fc1(x)\n",
    "        bn1 = self.bn1(fc1)\n",
    "        self.hid1 = torch.tanh(bn1)\n",
    "        fc2 = self.dropout(self.hid1)\n",
    "        fc2 = self.fc2(self.hid1)\n",
    "        bn2 = self.bn2(fc2)\n",
    "        self.hid2 = torch.tanh(bn2)\n",
    "        fc2 = self.dropout(self.hid2)\n",
    "        fc3 = self.fc3(self.hid2)\n",
    "        bn3 = self.bn3(fc3)\n",
    "        self.hid3 = torch.tanh(bn3)\n",
    "        res = self.dropout(self.hid3)\n",
    "        out = self.out(res)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural network consist of 3 hidden layers with each having 64 hidden nodes, an output layer with 9 nodes to represent the number of unique classes and an input layer with 93 nodes that represent the amount of unique features.\n",
    "\n",
    "Note that there is no activation applied to \"out\" above as we will be using the CrossEntropyLoss() function provided by pytorch and by default it will apply log_softmax to calculate the loss.\n",
    "\n",
    "BatchNormalization and Dropout was used in order to prevent the network from training an overfitting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Loss Function\n",
    "\n",
    "def log_loss(y_pred, y_label, eps=1e-15):\n",
    "    y_label = y_label.view(-1,1).long()\n",
    "    res = torch.gather(y_pred, 1,y_label)\n",
    "    res = torch.clamp(res, eps, 1-eps)\n",
    "    res = -torch.log(res)\n",
    "    res = torch.mean(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testAccuracy(net, feat, expected, device):\n",
    "    net.eval() # Set network to evaluation mode\n",
    "    X = feat\n",
    "    y = expected\n",
    "    X = X.to(device)\n",
    "    output = net(X)\n",
    "    \n",
    "    correct, total = 0, 0\n",
    "    for idx, i in enumerate(output):  \n",
    "        if torch.argmax(i) == y[idx]:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "        \n",
    "    accuracy = round(correct/total,3)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "Final Result\n",
      "--------------------------------------------------\n",
      "EPOCH:  15\n",
      "Train Loss: 0.5592359900474548, Train Accuracy: 0.822\n",
      "Validation Score:  0.799\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "        \n",
    "\n",
    "def trainNet(epoch, lrate, hidden, dropout):\n",
    "\n",
    "    net = Net(hidden, dropout).to(device)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lrate)\n",
    "    \n",
    "\n",
    "    EPOCHS = epoch\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        for data in train_loader:\n",
    "            net.train()\n",
    "            X, y = data\n",
    "            y = y.type(torch.LongTensor)\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            net.zero_grad()\n",
    "            output = net(X)\n",
    "            #res = log_loss(output, y)\n",
    "            loss = nn.CrossEntropyLoss()    \n",
    "            res = loss(output, y)\n",
    "            res.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_loss = res.item()\n",
    "    \n",
    "    return net, train_loss\n",
    "\n",
    "def printResult(model, epoch, train_loss):\n",
    "    train_acc = testAccuracy(model, trainX, trainY, device)\n",
    "    val_acc = testAccuracy(model, valX, valY, device)\n",
    "    print('Final Result')\n",
    "    print('--------------------------------------------------')\n",
    "    print(\"EPOCH: \", epoch)\n",
    "    print(\"Train Loss: {}, Train Accuracy: {}\".format(train_loss, train_acc))\n",
    "    print(\"Validation Score: \", val_acc)\n",
    "\n",
    "net, train_loss = trainNet(15, 0.001, 100, 0.5)\n",
    "printResult(net, 15, train_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Trained Model on the Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Class_1</th>\n",
       "      <th>Class_2</th>\n",
       "      <th>Class_3</th>\n",
       "      <th>Class_4</th>\n",
       "      <th>Class_5</th>\n",
       "      <th>Class_6</th>\n",
       "      <th>Class_7</th>\n",
       "      <th>Class_8</th>\n",
       "      <th>Class_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.467416</td>\n",
       "      <td>0.396190</td>\n",
       "      <td>0.125184</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.009995</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000804</td>\n",
       "      <td>0.004192</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>0.886278</td>\n",
       "      <td>0.003433</td>\n",
       "      <td>0.102150</td>\n",
       "      <td>0.001878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.999339</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.000052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.784220</td>\n",
       "      <td>0.208069</td>\n",
       "      <td>0.004867</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.000889</td>\n",
       "      <td>0.000598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.043109</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.002955</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.065360</td>\n",
       "      <td>0.886776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   Class_1   Class_2   Class_3   Class_4   Class_5   Class_6   Class_7  \\\n",
       "0   1  0.000485  0.467416  0.396190  0.125184  0.000174  0.000300  0.009995   \n",
       "1   2  0.000804  0.004192  0.000597  0.000357  0.000311  0.886278  0.003433   \n",
       "2   3  0.000031  0.000006  0.000004  0.000028  0.000011  0.999339  0.000216   \n",
       "3   4  0.000496  0.784220  0.208069  0.004867  0.000675  0.000039  0.000148   \n",
       "4   5  0.043109  0.000301  0.000222  0.000012  0.000154  0.002955  0.001111   \n",
       "\n",
       "    Class_8   Class_9  \n",
       "0  0.000085  0.000171  \n",
       "1  0.102150  0.001878  \n",
       "2  0.000313  0.000052  \n",
       "3  0.000889  0.000598  \n",
       "4  0.065360  0.886776  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gets test data and separates into X,Y values.\n",
    "test = pd.read_csv(\"data/test.csv\")\n",
    "ids = test.iloc[:, 0]\n",
    "test = test.iloc[:,1:]     # remove ID and Label \n",
    "\n",
    "# Convert test set into tensor form with Pytorch functions\n",
    "test = torch.tensor(test.values) \n",
    "\n",
    "# Convert values to type float\n",
    "test = test.type(torch.FloatTensor)\n",
    "\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    X = test\n",
    "    X = X.to(device)\n",
    "    output = net(X)\n",
    "\n",
    "output = F.softmax(output, dim=1)\n",
    "output = output.to(\"cpu\")\n",
    "output = output.numpy()\n",
    "\n",
    "for x in output:\n",
    "    for i in range(len(x)):\n",
    "        x[i] = x[i].item()\n",
    "\n",
    "\n",
    "test_set = pd.DataFrame(output)\n",
    "\n",
    "for i in range(1, 10):\n",
    "    col = 'Class_' + str(i)\n",
    "    test_set = test_set.rename(columns={i-1: col})\n",
    "\n",
    "test_set.insert(0, 'id', ids)\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.to_csv('nn_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By submitting the results of our test set onto Kaggle, we were able to obtain a public score of 0.51377 and private score of 0.51970 which puts us in position 1550 and 1570 respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning for Performance Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import UnivariateSpline\n",
    "\n",
    "def plotNet(x, y, x_min, x_max, y_min, y_max, \n",
    "            lin_space, title, x_label, y_label,\n",
    "            desc, best, acc):\n",
    "    plt.axis([x_min, x_max, y_min, y_max])\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(title)\n",
    "    \n",
    "    s = UnivariateSpline(x, y, s=5)\n",
    "    xs = np.linspace(0, lin_space, len(x))\n",
    "    ys = s(xs)\n",
    "    plt.scatter(x, y)\n",
    "    plt.plot(xs, ys, color='orange')\n",
    "    plot_min(desc, best, acc)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def plot_min(desc, x, y):\n",
    "    text= \"Best {}={:.2f}, Accuracy={}\".format(desc, x, y)\n",
    "    bbox_props = dict(boxstyle=\"square,pad=0.3\", fc=\"w\", ec=\"k\", lw=0.72)\n",
    "    arrowprops=dict(arrowstyle=\"->\",connectionstyle=\"angle,angleA=0,angleB=60\")\n",
    "    kw = dict(xycoords='data',textcoords=\"axes fraction\", bbox=bbox_props, ha=\"right\", va=\"top\")\n",
    "    plt.annotate(text, xy=(x, y), xytext=(0.94,0.96), **kw)\n",
    "    plt.savefig(\"{}.png\".format(desc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout vs No Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "x_dp = []\n",
    "y_dp = []\n",
    "\n",
    "for dp in np.arange(0, 1.0, 0.1):\n",
    "    model, train_loss = trainNet(15, 0.001, 100, dp)\n",
    "    val_acc = testAccuracy(model, valX, valY, device)\n",
    "    x_dp.append(dp)\n",
    "    y_dp.append(round(val_acc, 3))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = y_dp.index(max(y_dp))\n",
    "plotNet(x_dp, y_dp, 0, 1, 0.7, 0.85, 1.0, \n",
    "        \"Hyperparameter Testing: Dropout\", \"Dropout Rate\", \"Accuracy\",\n",
    "        \"Dropout\", x_dp[index], y_dp[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Hidden Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-bca79b0103c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mhid\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mval_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtestAccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mx_hid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-4d6f80fb5376>\u001b[0m in \u001b[0;36mtrainNet\u001b[1;34m(epoch, lrate, hidden, dropout)\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m             \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;31m#res = log_loss(output, y)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mzero_grad\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1114\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1115\u001b[0m                 \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1116\u001b[1;33m                 \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mshare_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x_hid = []\n",
    "y_hid = []\n",
    "\n",
    "for hid in np.arange(8, 128, 8):\n",
    "    model, train_loss = trainNet(15, 0.001, hid, 0.5)\n",
    "    val_acc = testAccuracy(model, valX, valY, device)\n",
    "    x_hid.append(hid)\n",
    "    y_hid.append(round(val_acc, 3))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = y_hid.index(max(y_hid))\n",
    "plotNet(x_hid, y_hid, 0, 128, 0.7, 0.85, 128,\n",
    "        \"Hyperparameter Testing: Hidden Nodes\", \"Hidden Nodes\", \"Accuracy\",\n",
    "        \"Hidden Nodes\", x_hid[index], y_hid[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_res = []\n",
    "y_res = []\n",
    "\n",
    "# God running this took nearly an hour lol\n",
    "for lr in np.arange(0.001, 0.11, 0.001):\n",
    "    model, train_loss = trainNet(10, lr, 100, 0.5)\n",
    "    val_acc = testAccuracy(model, valX, valY, device)\n",
    "    x_res.append(lr)\n",
    "    y_res.append(round(val_acc, 3))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = y_res.index(max(y_res))\n",
    "plotNet(x_res, y_res, 0, 128, 0.7, 0.85, 128,\n",
    "        \"Hyperparameter Testing: Hidden Nodes\", \"Hidden Nodes\", \"Accuracy\",\n",
    "        \"Hidden Nodes\", x_res[index], y_res[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model with Hyperparameters Tuning Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net, train_loss = trainNet(15, 0.002, 96, 0.4)\n",
    "printResult(net, 15, train_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Optimized Model on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    X = test\n",
    "    X = X.to(device)\n",
    "    output = net(X)\n",
    "\n",
    "output = F.softmax(output, dim=1)\n",
    "output = output.to(\"cpu\")\n",
    "output = output.numpy()\n",
    "\n",
    "for x in output:\n",
    "    for i in range(len(x)):\n",
    "        x[i] = x[i].item()\n",
    "\n",
    "\n",
    "test_set = pd.DataFrame(output)\n",
    "\n",
    "for i in range(1, 10):\n",
    "    col = 'Class_' + str(i)\n",
    "    test_set = test_set.rename(columns={i-1: col})\n",
    "\n",
    "test_set.insert(0, 'id', ids)\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.to_csv('nn_optimized.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
